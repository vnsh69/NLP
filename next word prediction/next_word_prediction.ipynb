{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading the data\n",
    "with open(\"1661-0.txt\", \"r\") as file:\n",
    "    text = file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8923"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tokenizing the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating training sample where each sequence gets progressively increase\n",
    "sequences = []\n",
    "for line in text.split('.'):  ## spliting new sentences\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]  ## converting word(sentence) to tokenized list\n",
    "    for i in range (1,len(token_list)):  ## start from 1 bcs it ensure that list atleast have 2 words(token)\n",
    "        n_gram_sequence = token_list[:i+1]    \n",
    "        sequences.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n"
     ]
    }
   ],
   "source": [
    "max_sequence_len = max(len(x) for x in sequences)\n",
    "print(max_sequence_len)\n",
    "\n",
    "## padding to sequence so that input size is fixed\n",
    "input_sequence = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = input_sequence[:,:-1], input_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.keras.utils.to_categorical(y, num_classes = total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='accuracy',  restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating model using LSTM\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len - 1),\n",
    "    LSTM(100),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(total_words, activation='softmax')  ## Predict next word\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 104, 100)          892300    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 100)              400       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8923)              901223    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,884,423\n",
      "Trainable params: 1,884,223\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "2616/2616 [==============================] - 43s 14ms/step - loss: 6.3115 - accuracy: 0.0913\n",
      "Epoch 2/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 5.5059 - accuracy: 0.1349\n",
      "Epoch 3/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 5.1029 - accuracy: 0.1550\n",
      "Epoch 4/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 4.7944 - accuracy: 0.1737\n",
      "Epoch 5/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 4.5355 - accuracy: 0.1892\n",
      "Epoch 6/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 4.3141 - accuracy: 0.2038\n",
      "Epoch 7/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 4.1275 - accuracy: 0.2180\n",
      "Epoch 8/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 3.9550 - accuracy: 0.2303\n",
      "Epoch 9/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.8135 - accuracy: 0.2434\n",
      "Epoch 10/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.6810 - accuracy: 0.2542\n",
      "Epoch 11/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.5662 - accuracy: 0.2667\n",
      "Epoch 12/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 3.4583 - accuracy: 0.2778\n",
      "Epoch 13/120\n",
      "2616/2616 [==============================] - 55s 21ms/step - loss: 3.3677 - accuracy: 0.2901\n",
      "Epoch 14/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.2821 - accuracy: 0.3033\n",
      "Epoch 15/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.2059 - accuracy: 0.3119\n",
      "Epoch 16/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.1323 - accuracy: 0.3242\n",
      "Epoch 17/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.0635 - accuracy: 0.3333\n",
      "Epoch 18/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 3.0056 - accuracy: 0.3411\n",
      "Epoch 19/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.9454 - accuracy: 0.3513\n",
      "Epoch 20/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.8950 - accuracy: 0.3569\n",
      "Epoch 21/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.8421 - accuracy: 0.3663\n",
      "Epoch 22/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.8028 - accuracy: 0.3723\n",
      "Epoch 23/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.7454 - accuracy: 0.3822\n",
      "Epoch 24/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.7113 - accuracy: 0.3875\n",
      "Epoch 25/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.6697 - accuracy: 0.3937\n",
      "Epoch 26/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.6377 - accuracy: 0.3994\n",
      "Epoch 27/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.5959 - accuracy: 0.4066\n",
      "Epoch 28/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.5650 - accuracy: 0.4114\n",
      "Epoch 29/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.5319 - accuracy: 0.4176\n",
      "Epoch 30/120\n",
      "2616/2616 [==============================] - 36s 14ms/step - loss: 2.5074 - accuracy: 0.4206\n",
      "Epoch 31/120\n",
      "2616/2616 [==============================] - 39s 15ms/step - loss: 2.4602 - accuracy: 0.4284\n",
      "Epoch 32/120\n",
      "2616/2616 [==============================] - 41s 16ms/step - loss: 2.4341 - accuracy: 0.4333\n",
      "Epoch 33/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.4184 - accuracy: 0.4368\n",
      "Epoch 34/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.3863 - accuracy: 0.4431\n",
      "Epoch 35/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.3551 - accuracy: 0.4478\n",
      "Epoch 36/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.3319 - accuracy: 0.4524\n",
      "Epoch 37/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.3109 - accuracy: 0.4565\n",
      "Epoch 38/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.2925 - accuracy: 0.4598\n",
      "Epoch 39/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.2744 - accuracy: 0.4634\n",
      "Epoch 40/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.2442 - accuracy: 0.4709\n",
      "Epoch 41/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.2213 - accuracy: 0.4700\n",
      "Epoch 42/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.2052 - accuracy: 0.4763\n",
      "Epoch 43/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.1887 - accuracy: 0.4775\n",
      "Epoch 44/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.1723 - accuracy: 0.4831\n",
      "Epoch 45/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.1462 - accuracy: 0.4881\n",
      "Epoch 46/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.1370 - accuracy: 0.4885\n",
      "Epoch 47/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.1114 - accuracy: 0.4925\n",
      "Epoch 48/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0926 - accuracy: 0.4955\n",
      "Epoch 49/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0878 - accuracy: 0.4990\n",
      "Epoch 50/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0653 - accuracy: 0.5021\n",
      "Epoch 51/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0497 - accuracy: 0.5062\n",
      "Epoch 52/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0309 - accuracy: 0.5092\n",
      "Epoch 53/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0158 - accuracy: 0.5119\n",
      "Epoch 54/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 2.0117 - accuracy: 0.5133\n",
      "Epoch 55/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9940 - accuracy: 0.5165\n",
      "Epoch 56/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9782 - accuracy: 0.5206\n",
      "Epoch 57/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9730 - accuracy: 0.5190\n",
      "Epoch 58/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9603 - accuracy: 0.5223\n",
      "Epoch 59/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9485 - accuracy: 0.5256\n",
      "Epoch 60/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9312 - accuracy: 0.5280\n",
      "Epoch 61/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9181 - accuracy: 0.5314\n",
      "Epoch 62/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9179 - accuracy: 0.5315\n",
      "Epoch 63/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.9055 - accuracy: 0.5344\n",
      "Epoch 64/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8897 - accuracy: 0.5374\n",
      "Epoch 65/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8793 - accuracy: 0.5391\n",
      "Epoch 66/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8721 - accuracy: 0.5417\n",
      "Epoch 67/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8619 - accuracy: 0.5429\n",
      "Epoch 68/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8474 - accuracy: 0.5458\n",
      "Epoch 69/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8386 - accuracy: 0.5465\n",
      "Epoch 70/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8221 - accuracy: 0.5513\n",
      "Epoch 71/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8192 - accuracy: 0.5526\n",
      "Epoch 72/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8071 - accuracy: 0.5546\n",
      "Epoch 73/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.8058 - accuracy: 0.5538\n",
      "Epoch 74/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7864 - accuracy: 0.5586\n",
      "Epoch 75/120\n",
      "2616/2616 [==============================] - 42s 16ms/step - loss: 1.7809 - accuracy: 0.5584\n",
      "Epoch 76/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7773 - accuracy: 0.5598\n",
      "Epoch 77/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7669 - accuracy: 0.5613\n",
      "Epoch 78/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7601 - accuracy: 0.5635\n",
      "Epoch 79/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7402 - accuracy: 0.5663\n",
      "Epoch 80/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7519 - accuracy: 0.5655\n",
      "Epoch 81/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.7374 - accuracy: 0.5676\n",
      "Epoch 82/120\n",
      "2616/2616 [==============================] - 29s 11ms/step - loss: 1.7242 - accuracy: 0.5719\n",
      "Epoch 83/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.7257 - accuracy: 0.5723\n",
      "Epoch 84/120\n",
      "2616/2616 [==============================] - 59s 22ms/step - loss: 1.7092 - accuracy: 0.5735\n",
      "Epoch 85/120\n",
      "2616/2616 [==============================] - 65s 25ms/step - loss: 1.7051 - accuracy: 0.5742\n",
      "Epoch 86/120\n",
      "2616/2616 [==============================] - 44s 17ms/step - loss: 1.7024 - accuracy: 0.5762\n",
      "Epoch 87/120\n",
      "2616/2616 [==============================] - 25s 9ms/step - loss: 1.6929 - accuracy: 0.5763\n",
      "Epoch 88/120\n",
      "2616/2616 [==============================] - 25s 9ms/step - loss: 1.6857 - accuracy: 0.5788\n",
      "Epoch 89/120\n",
      "2616/2616 [==============================] - 25s 10ms/step - loss: 1.6755 - accuracy: 0.5819\n",
      "Epoch 90/120\n",
      "2616/2616 [==============================] - 25s 9ms/step - loss: 1.6795 - accuracy: 0.5806\n",
      "Epoch 91/120\n",
      "2616/2616 [==============================] - 25s 9ms/step - loss: 1.6590 - accuracy: 0.5843\n",
      "Epoch 92/120\n",
      "2616/2616 [==============================] - 25s 9ms/step - loss: 1.6631 - accuracy: 0.5857\n",
      "Epoch 93/120\n",
      "2616/2616 [==============================] - 25s 10ms/step - loss: 1.6520 - accuracy: 0.5867\n",
      "Epoch 94/120\n",
      "2616/2616 [==============================] - 26s 10ms/step - loss: 1.6495 - accuracy: 0.5885\n",
      "Epoch 95/120\n",
      "2616/2616 [==============================] - 26s 10ms/step - loss: 1.6415 - accuracy: 0.5900\n",
      "Epoch 96/120\n",
      "2616/2616 [==============================] - 24s 9ms/step - loss: 1.6383 - accuracy: 0.5899\n",
      "Epoch 97/120\n",
      "2616/2616 [==============================] - 24s 9ms/step - loss: 1.6297 - accuracy: 0.5903\n",
      "Epoch 98/120\n",
      "2616/2616 [==============================] - 24s 9ms/step - loss: 1.6169 - accuracy: 0.5947\n",
      "Epoch 99/120\n",
      "2616/2616 [==============================] - 24s 9ms/step - loss: 1.6092 - accuracy: 0.5963\n",
      "Epoch 100/120\n",
      "2616/2616 [==============================] - 24s 9ms/step - loss: 1.6085 - accuracy: 0.5952\n",
      "Epoch 101/120\n",
      "2616/2616 [==============================] - 22s 9ms/step - loss: 1.6091 - accuracy: 0.5958\n",
      "Epoch 102/120\n",
      "2616/2616 [==============================] - 22s 8ms/step - loss: 1.6020 - accuracy: 0.6003\n",
      "Epoch 103/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5951 - accuracy: 0.5992\n",
      "Epoch 104/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5917 - accuracy: 0.6019\n",
      "Epoch 105/120\n",
      "2616/2616 [==============================] - 37s 14ms/step - loss: 1.5769 - accuracy: 0.6042\n",
      "Epoch 106/120\n",
      "2616/2616 [==============================] - 66s 25ms/step - loss: 1.5718 - accuracy: 0.6047\n",
      "Epoch 107/120\n",
      "2616/2616 [==============================] - 65s 25ms/step - loss: 1.5766 - accuracy: 0.6036\n",
      "Epoch 108/120\n",
      "2616/2616 [==============================] - 48s 18ms/step - loss: 1.5780 - accuracy: 0.6032\n",
      "Epoch 109/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5639 - accuracy: 0.6062\n",
      "Epoch 110/120\n",
      "2616/2616 [==============================] - 22s 9ms/step - loss: 1.5587 - accuracy: 0.6072\n",
      "Epoch 111/120\n",
      "2616/2616 [==============================] - 22s 9ms/step - loss: 1.5586 - accuracy: 0.6067\n",
      "Epoch 112/120\n",
      "2616/2616 [==============================] - 22s 8ms/step - loss: 1.5448 - accuracy: 0.6110\n",
      "Epoch 113/120\n",
      "2616/2616 [==============================] - 22s 8ms/step - loss: 1.5462 - accuracy: 0.6112\n",
      "Epoch 114/120\n",
      "2616/2616 [==============================] - 22s 8ms/step - loss: 1.5469 - accuracy: 0.6107\n",
      "Epoch 115/120\n",
      "2616/2616 [==============================] - 22s 9ms/step - loss: 1.5316 - accuracy: 0.6117\n",
      "Epoch 116/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5371 - accuracy: 0.6119\n",
      "Epoch 117/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5221 - accuracy: 0.6161\n",
      "Epoch 118/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5183 - accuracy: 0.6162\n",
      "Epoch 119/120\n",
      "2616/2616 [==============================] - 22s 8ms/step - loss: 1.5097 - accuracy: 0.6193\n",
      "Epoch 120/120\n",
      "2616/2616 [==============================] - 23s 9ms/step - loss: 1.5149 - accuracy: 0.6178\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, input_text, tokenizer, max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    if len(token_list)>=max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]\n",
    "    \n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list)\n",
    "    predicted_max_index = np.argmax(predicted,axis=1)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_max_index:\n",
    "            return word\n",
    "        \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 472ms/step\n",
      "The note was undated, and without either signature or ,prediction: address\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The note was undated, and without either signature or\"\n",
    "word = predict_next_word(model=model, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "Peculiar—that is the very word,” said ,prediction: holmes\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Peculiar—that is the very word,” said\"\n",
    "word = predict_next_word(model=model, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "“Very, indeed. And what does she propose to do with the ,prediction: photograph\n"
     ]
    }
   ],
   "source": [
    "input_text = \"“Very, indeed. And what does she propose to do with the\"\n",
    "word = predict_next_word(model=model, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model.save(\"next_word_predition.h5\")\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating model using bidirectional GRU\n",
    "model_bidirectonal = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=50, input_length=max_sequence_len - 1),\n",
    "    Bidirectional(GRU(160, return_sequences=True)),\n",
    "    Dropout(0.2),   \n",
    "    Bidirectional(GRU(80, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(GRU(80)),\n",
    "    Dense(total_words, activation='softmax')  ## Predict next word\n",
    "])\n",
    "\n",
    "model_bidirectonal.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 104, 50)           446150    \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 104, 320)         203520    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 104, 320)          0         \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 104, 160)         192960    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 104, 160)          0         \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 160)              116160    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8923)              1436603   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,395,393\n",
      "Trainable params: 2,395,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_bidirectonal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2616/2616 [==============================] - 130s 48ms/step - loss: 6.5012 - accuracy: 0.0665 - val_loss: 6.1981 - val_accuracy: 0.0798\n",
      "Epoch 2/50\n",
      "2616/2616 [==============================] - 153s 58ms/step - loss: 5.8908 - accuracy: 0.0934 - val_loss: 5.9820 - val_accuracy: 0.1042\n",
      "Epoch 3/50\n",
      "2616/2616 [==============================] - 153s 59ms/step - loss: 5.5845 - accuracy: 0.1143 - val_loss: 5.8943 - val_accuracy: 0.1173\n",
      "Epoch 4/50\n",
      "2616/2616 [==============================] - 135s 52ms/step - loss: 5.3654 - accuracy: 0.1256 - val_loss: 5.8941 - val_accuracy: 0.1239\n",
      "Epoch 5/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 5.1821 - accuracy: 0.1353 - val_loss: 5.8851 - val_accuracy: 0.1285\n",
      "Epoch 6/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 5.0178 - accuracy: 0.1449 - val_loss: 5.8941 - val_accuracy: 0.1348\n",
      "Epoch 7/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 4.8678 - accuracy: 0.1518 - val_loss: 5.9159 - val_accuracy: 0.1354\n",
      "Epoch 8/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.7196 - accuracy: 0.1592 - val_loss: 5.9485 - val_accuracy: 0.1389\n",
      "Epoch 9/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.5840 - accuracy: 0.1637 - val_loss: 6.0050 - val_accuracy: 0.1387\n",
      "Epoch 10/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.4565 - accuracy: 0.1696 - val_loss: 6.0318 - val_accuracy: 0.1378\n",
      "Epoch 11/50\n",
      "2616/2616 [==============================] - 140s 53ms/step - loss: 4.3420 - accuracy: 0.1761 - val_loss: 6.0805 - val_accuracy: 0.1401\n",
      "Epoch 12/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.2242 - accuracy: 0.1824 - val_loss: 6.1633 - val_accuracy: 0.1382\n",
      "Epoch 13/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.1239 - accuracy: 0.1911 - val_loss: 6.1827 - val_accuracy: 0.1383\n",
      "Epoch 14/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 4.0261 - accuracy: 0.1995 - val_loss: 6.2631 - val_accuracy: 0.1365\n",
      "Epoch 15/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 3.9410 - accuracy: 0.2074 - val_loss: 6.2991 - val_accuracy: 0.1377\n",
      "Epoch 16/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.8596 - accuracy: 0.2155 - val_loss: 6.3629 - val_accuracy: 0.1376\n",
      "Epoch 17/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.7848 - accuracy: 0.2231 - val_loss: 6.4107 - val_accuracy: 0.1363\n",
      "Epoch 18/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.7117 - accuracy: 0.2309 - val_loss: 6.4516 - val_accuracy: 0.1373\n",
      "Epoch 19/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 3.6386 - accuracy: 0.2406 - val_loss: 6.5052 - val_accuracy: 0.1328\n",
      "Epoch 20/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.5809 - accuracy: 0.2474 - val_loss: 6.5432 - val_accuracy: 0.1325\n",
      "Epoch 21/50\n",
      "2616/2616 [==============================] - 140s 54ms/step - loss: 3.5181 - accuracy: 0.2539 - val_loss: 6.6145 - val_accuracy: 0.1377\n",
      "Epoch 22/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.4637 - accuracy: 0.2612 - val_loss: 6.6186 - val_accuracy: 0.1347\n",
      "Epoch 23/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.4069 - accuracy: 0.2666 - val_loss: 6.6948 - val_accuracy: 0.1307\n",
      "Epoch 24/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.3617 - accuracy: 0.2740 - val_loss: 6.6973 - val_accuracy: 0.1306\n",
      "Epoch 25/50\n",
      "2616/2616 [==============================] - 141s 54ms/step - loss: 3.3103 - accuracy: 0.2824 - val_loss: 6.7754 - val_accuracy: 0.1314\n"
     ]
    }
   ],
   "source": [
    "history_bidirectional = model_bidirectonal.fit(x_train, y_train, epochs=50,validation=(x_test,y_test) callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model, input_text, tokenizer, max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([input_text])[0]\n",
    "    if len(token_list)>=max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]\n",
    "    \n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list)\n",
    "    predicted_max_index = np.argmax(predicted,axis=1)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_max_index:\n",
    "            return word\n",
    "        \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "The note was undated, and without either signature or ,prediction: the\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The note was undated, and without either signature or\"\n",
    "word = predict_next_word(model=model_bidirectonal, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "Peculiar—that is the very word,” said ,prediction: holmes\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Peculiar—that is the very word,” said\"\n",
    "word = predict_next_word(model=model_bidirectonal, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "“Very, indeed. And what does she propose to do with the ,prediction: door\n"
     ]
    }
   ],
   "source": [
    "input_text = \"“Very, indeed. And what does she propose to do with the\"\n",
    "word = predict_next_word(model=model_bidirectonal, input_text=input_text, tokenizer=tokenizer, max_sequence_len=max_sequence_len)\n",
    "print(f\"{input_text} ,prediction: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_bidirectonal.save(\"next_word_predition_using_Bidirectional.h5\")\n",
    "with open('tokenizer.pickle','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
